{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DateType\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import time\n",
    "from pyspark.sql import SparkSession, types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_public_holidays(start_year, end_year, country_code):\n",
    "    url = \"https://date.nager.at/api/v3/publicholidays/\"\n",
    "    holidays_data = []\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        api_url = f\"{url}{year}/{country_code}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(api_url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                # Convertir la fecha de string a datetime.date\n",
    "                for holiday in data:\n",
    "                    holiday_date = datetime.strptime(holiday[\"date\"], \"%Y-%m-%d\").date()  # Conversión de fecha\n",
    "                    holidays_data.append((holiday_date, holiday[\"localName\"]))\n",
    "            else:\n",
    "                print(f\"Failed to retrieve data for {year}, status code: {response.status_code}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "        \n",
    "        time.sleep(1)  # Para evitar sobrecargar el servidor con solicitudes\n",
    "\n",
    "    # Definir el esquema para el DataFrame de Spark\n",
    "    schema = T.StructType([\n",
    "        T.StructField(\"fecha\", T.DateType(), True),\n",
    "        T.StructField(\"nombre_del_festivo\", T.StringType(), True)\n",
    "    ])\n",
    "\n",
    "    # Crear el DataFrame de Spark con los datos de festivos\n",
    "    holidays_df = spark.createDataFrame(holidays_data, schema=schema)\n",
    "    \n",
    "    return holidays_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generar_calendario(anio_inicio, anio_fin):\n",
    "    # Crear un rango de fechas\n",
    "    fecha_inicio = datetime(anio_inicio, 1, 1)\n",
    "    fecha_fin = datetime(anio_fin, 12, 31)\n",
    "    num_dias = (fecha_fin - fecha_inicio).days + 1\n",
    "    fechas = [(fecha_inicio + timedelta(days=x)) for x in range(num_dias)]\n",
    "    \n",
    "    # Crear un DataFrame de Spark con la lista de fechas\n",
    "    calendario_df = spark.createDataFrame(fechas, DateType()).toDF(\"fecha\")\n",
    "\n",
    "    # Agregar columnas de año, mes, semana y día de la semana\n",
    "    calendario_df = (calendario_df\n",
    "                     .withColumn(\"año\", F.year(\"fecha\"))\n",
    "                     .withColumn(\"mes\", F.month(\"fecha\"))\n",
    "                     .withColumn(\"semana\", F.weekofyear(\"fecha\"))\n",
    "                     .withColumn(\"dia_de_la_semana\", F.dayofweek(\"fecha\")))\n",
    "\n",
    "    # Ajustar para que el lunes sea 1 y domingo 7\n",
    "    calendario_df = calendario_df.withColumn(\"dia_de_la_semana\", \n",
    "                                             F.when(F.col(\"dia_de_la_semana\") == 1, 7)\n",
    "                                             .otherwise(F.col(\"dia_de_la_semana\") - 1))\n",
    "    \n",
    "    # Ordenar el DataFrame por fecha de menor a mayor\n",
    "    calendario_df = calendario_df.orderBy(\"fecha\")\n",
    "\n",
    "    return calendario_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ejecución de las funciones\n",
    "public_holidays_data = get_public_holidays(start_year, end_year, country_code)\n",
    "calendario = generar_calendario(start_year, end_year)\n",
    "\n",
    "# Unir calendario y festivos en Spark\n",
    "calendario = calendario.join(public_holidays_data, on=\"fecha\", how=\"left\")\n",
    "\n",
    "# Agregar columna de festivo ('Sí' o 'No')\n",
    "calendario = calendario.withColumn(\"festivo\", F.when(F.col(\"nombre_del_festivo\").isNotNull(), \"Sí\").otherwise(\"No\"))\n",
    "\n",
    "# Agregar columna de día hábil ('Sí' o 'No')\n",
    "calendario = calendario.withColumn(\n",
    "    \"dia_habil\",\n",
    "    F.when((F.col(\"dia_de_la_semana\") <= 5) & (F.col(\"festivo\") == \"No\"), \"Sí\").otherwise(\"No\")\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
